---
title: "In Class Example"
author: "Scott Stoltzman"
date: "8/12/2019"
output: html_document
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library('stringi')
library('tidyverse')
library('tidytext')
library('syuzhet')
library('caret')
data("stop_words")
set.seed(123)
```

## Load Data
```{r}
raw_dat = read_csv('https://foco-ds-portal-files.s3.amazonaws.com/IMDB+Dataset.csv') %>%
  rename(reviewer_recommended = sentiment) %>%
  mutate(reviewer_recommended = str_replace(reviewer_recommended, 'positive', 'yes'),
         reviewer_recommended = str_replace(reviewer_recommended, 'negative', 'no')) %>%
  mutate(id = row_number())
  

raw_dat = raw_dat %>%
  sample_n(10000)
```

## Wrangle Data
```{r}
dat = raw_dat %>%
  mutate(sentiment = get_sentiment(review),
         number_of_words = stri_count(review, regex="\\S+"),
         number_of_letters = nchar(review),
         avg_word_length = number_of_letters / number_of_words) %>%
  select(id, reviewer_recommended, sentiment, 
         number_of_words, number_of_letters,avg_word_length)

head(dat)
```

## EDA
```{r}
dat %>%
  ggplot(aes(x = sentiment, col = reviewer_recommended, fill = reviewer_recommended)) +
  geom_density(alpha = 0.5)
```

## Text wrangling
```{r}
text_dat_raw = raw_dat %>%
  unnest_tokens(word, review) %>%
  anti_join(stop_words, by = 'word') %>%
  mutate(word = str_extract(word, "[a-z']+")) %>%
  filter(word != 'br') %>%
  filter(word != 'movie') %>%
  filter(word != 'film')

text_dat_grouped = text_dat_raw %>%
  group_by(reviewer_recommended, id, word) %>%
  summarize(n = 1) %>%
  group_by(reviewer_recommended, word) %>%
  summarize(n = n()) %>%
  group_by(word) %>%
  mutate(pct_of_total = n / sum(n)) %>%
  ungroup() %>%
  filter(n > 100, 
         pct_of_total > 0.70) %>% # must be in +70% favor of one review type
  select(word)

text_dat_spread = text_dat_grouped %>% 
  left_join(text_dat_raw, by = 'word') %>%
  select(id, word) %>%
  distinct(id, word) %>%
  mutate(n = 1) %>%
  spread(key = word, value = n)

head(text_dat_spread)
```

## Join dat & text_dat
```{r}
final_dat = dat %>%
  left_join(text_dat_spread, by = 'id')

final_dat[is.na(final_dat)] = 0

head(final_dat)
```



## Build model

```{r}
dat_train = final_dat %>%
  group_by(reviewer_recommended) %>% # evenly balanced data set
  sample_n(1000) %>%
  ungroup()

dat_test = anti_join(final_dat, dat_train, by = 'id')
  
dat_test = dat_test %>% select(-id)
dat_train = dat_train %>% select(-id)
```


```{r}
train_control = trainControl(method = "oob")

model_rf = train(dat_train %>% select(-reviewer_recommended),
            dat_train$reviewer_recommended,
            method = "ranger",
            num.trees = 50,
            importance = "impurity",
            trControl = train_control)

predictions_rf = predict(model_rf, dat_test)
confusionMatrix(predictions_rf, as.factor(dat_test$reviewer_recommended))
```


```{r}
model_rf$finalModel %>%
  # extract variable importance metrics
  ranger::importance() %>%
  # convert to a data frame
  enframe(name = "variable", value = "varimp") %>%
  top_n(n = 20, wt = varimp) %>%
  # plot the metrics
  ggplot(aes(x = fct_reorder(variable, varimp), y = varimp)) +
  geom_col() +
  coord_flip() +
  labs(x = "Token",
       y = "Variable importance (higher is more important)")
```
